# Desafio de Data Engineer - IPLANRIO

Reposit√≥rio de instru√ß√£o para o desafio t√©cnico para vaga de Pessoa Engenheira de Dados.

## Descri√ß√£o do desafio

Neste desafio voc√™ dever√° capturar, estruturar, armazenar e transformar dados de Terceirizados de √ìrg√£os Federais, dispon√≠veis no site [Dados Abertos - Terceirizados de √ìrg√£os Federais](https://www.gov.br/cgu/pt-br/acesso-a-informacao/dados-abertos/arquivos/terceirizados).

Para o desafio, ser√° necess√°rio construir uma pipeline que realiza a extra√ß√£o, processamento e transforma√ß√£o dos dados. Voc√™ dever√° utilizar a arquitetura de medalh√£o para organizar os dados [^1]. Salve os dados de cada m√™s em arquivos Parquet (estruture os dados da maneira que achar mais conveniente, voc√™ tem liberdade para criar novas colunas ou particionar os dados), ent√£o carregue os dados em um bucket S3. Carregue os dados do bucket para um banco local DuckDB [^2], essa ser√° sua camada bronze. Usando DBT e DuckDB [^3], crie bancos locais com as camadas prata e ouro e suba os arquivos no mesmo bucket S3. A tabela derivada dever√° seguir a padroniza√ß√£o especificada no [manual de estilo da IPLANRIO](https://docs.dados.rio/data-lake/guia-de-estilo/convencoes-colunas). A solu√ß√£o devera contemplar o surgimento de novos dados a cada 4 meses, ou seja, deve ser idempotente e capaz de detectar e processar novos dados de maneira incremental.

Ao final do processo de ELT, a organiza√ß√£o do bucket S3 deve seguir algo semelhante a isso:

```
terceirizados/
‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ terceirizados_2025-01.parquet
‚îÇ   ‚îú‚îÄ‚îÄ terceirizados_2025-05.parquet
‚îÇ   ‚îú‚îÄ‚îÄ terceirizados_2025-07.parquet
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ bronze/
‚îÇ   ‚îî‚îÄ‚îÄ terceirizados-bronze.duckdb
‚îú‚îÄ‚îÄ silver/
‚îÇ   ‚îî‚îÄ‚îÄ terceirizados-silver.duckdb
‚îî‚îÄ‚îÄ gold/
    ‚îî‚îÄ‚îÄ terceirizados-gold.duckdb
```

Ap√≥s isso, crie uma API REST utilizando os dados da camada ouro, expondo os dados de maneira organizada e f√°cil de consumir. A API deve ter dois endpoints:

- `/terceirizados`: retorna a lista completa de terceirizados. Implemente pagina√ß√£o para evitar sobrecarga de dados.
- `/terceirizados/{id}`: retorna os detalhes de um terceirizado espec√≠fico, identificado pelo seu ID.

Dados que precisam estar presentes no endpoint `/terceirizados`:

- ID do terceirizado
- Sigla do √≥rg√£o superior da unidade gestora do terceirizado
- CNPJ da empresa terceirizada
- CPF do terceirizado

No endpoitnt `/terceirizados/{id}`, todos os dados presentes na camada ouro devem ser retornados [^4]. Implemente tamb√©m um mecanismo simples de cache para otimizar o desempenho da API, reduzindo o tempo de resposta para requisi√ß√µes frequentes. O acesso aos dados da camada ouro pode ser feito do modo que preferir, seja lendo diretamente do arquivo DuckDB direto do bucket ou carregando os dados para um banco de dados relacional (PostgreSQL, MySQL, etc.) e consultando a partir dele. A implementa√ß√£o de testes para a API √© opcional, mas ser√° considerada um diferencial. Adi√ß√£o de ferramentas de observabilidade e integra√ß√£o com [OpenTelemetry](https://opentelemetry.io/docs/) tamb√©m √© um diferencial.

## O que iremos avaliar

- **Completude**: a solu√ß√£o proposta atende a todos os requisitos do desafio?
- **Simplicidade**: a solu√ß√£o proposta √© simples e direta? √â f√°cil de entender e trabalhar?
- **Organiza√ß√£o**: a solu√ß√£o proposta √© organizada e bem documentada? √â f√°cil de navegar e encontrar o que se procura?
- **Criatividade**: a solu√ß√£o proposta √© criativa? Apresenta uma abordagem inovadora para o problema proposto?
- **Boas pr√°ticas**: a solu√ß√£o proposta segue boas pr√°ticas de Python, Git, Docker, etc.?

## Tecnologias obrigat√≥rias

- Docker e Docker Compose: para orquestra√ß√£o de containers
- Prefect (v3): para orquestra√ß√£o de pipelines
- DuckDB: para armazenamento e consulta dos dados
- DBT: para transforma√ß√£o dos dados
- Algum REST framework: voc√™ pode escolher a linguagem e o framework de sua prefer√™ncia (FastAPI, Flask, Express, Spring Boot, etc.)
- Git e GitHub: para controle de vers√£o e hospedagem do c√≥digo
- S3 (AWS S3, GCS, Backblaze B2, etc): para armazenamento dos arquivos Parquet [^5]

## Etapas

1. Subir o ambiente local com Docker Compose
2. Construir pipeline de ingest√£o
3. Persistir os dados mensais em arquivos Parquet particionados por m√™s
4. Fazer upload dos arquivos Parquet para um bucket S3 [^6]
5. Carregar os dados do bucket S3 para o DuckDB (camada bronze)
6. Criar camadas de dados via DBT, aplicando a padroniza√ß√£o de colunas conforme o guia da IPLANRIO
7. Fazer upload dos arquivos DuckDB para o bucket S3, organizando as camadas de dados (bronze, prata e ouro)
8. Criar uma API REST para expor os dados da camada ouro, implementando os endpoints `/terceirizados` e `/terceirizados/{id}` e um mecanismo de cache para otimizar o desempenho da API
9. Prever o surgimento de novos dados a cada ~4 meses (idempot√™ncia, reprocessamento incremental, detec√ß√£o de novidades)

## Instru√ß√µes extras

- Fa√ßa commits seguindo o padr√£o Conventional Commits
- Adicione metadados contendo descri√ß√µes detalhadas de cada modelo e campo usando as ferramentas dispon√≠veis no DBT
- Adicione testes de qualidade de dados no DBT
- Use uma estrutura de pastas e c√≥digo organizada e leg√≠vel
- Adicione instru√ß√µes claras de execu√ß√£o no README.md

## üö® Aten√ß√£o

- A solu√ß√£o desse desafio deve ser publicada em um fork deste reposit√≥rio no GitHub.
- O link do reposit√≥rio deve ser enviado para o e-mail utilizado para contato com o assunto "Desafio Data Engineer - IPLANRIO".
- Voc√™ deve ser capaz de apresentar sua solu√ß√£o, explicando como a idealizou, caso seja aprovado(a) para a pr√≥xima etapa.
- Caso n√£o consigamos replicar a solu√ß√£o proposta, ou caso haja problemas de acesso ao c√≥digo, dados ou infraestrutura utilizada, a solu√ß√£o n√£o ser√° avaliada e o candidato n√£o passar√° para a pr√≥xima etapa do processo seletivo.

## Links de refer√™ncia

- [Prefect](https://docs.prefect.io/v3/get-started)
- [DBT](https://docs.getdbt.com/docs/introduction)
- [Dados Abertos - Terceirizados de √ìrg√£os Federais](https://www.gov.br/cgu/pt-br/acesso-a-informacao/dados-abertos/arquivos/terceirizados)
- [Reposit√≥rio pipelines da IPLANRIO](https://github.com/prefeitura-rio/prefect_rj_iplanrio)
- [Reposit√≥rio de modelos DBT da IPLANRIO](https://github.com/prefeitura-rio/queries-rj-iplanrio/)
- [Manual de estilo da IPLANRIO](https://docs.dados.rio/data-lake/guia-de-estilo/convencoes-datasets-e-tabelas)

## D√∫vidas?

Fale conosco pelo e-mail que foi utilizado para o envio desse desafio.

[^1]: Guia: <https://www.databricks.com/glossary/medallion-architecture>

[^2]: Guia: <https://duckdb.org/docs/stable/guides/network_cloud_storage/s3_import>

[^3]: Guia: <https://docs.getdbt.com/docs/core/connect-data-platform/duckdb-setup>

[^4]: Sinta-se √† vontade para adicionar filtros, pagina√ß√£o ou outros mecanismos para otimizar o desempenho da API. Para mais informa√ß√µes, consulte a descri√ß√£o e o dicion√°rio de dados oficial: <https://www.gov.br/cgu/pt-br/acesso-a-informacao/dados-abertos/arquivos/terceirizados/arquivos/descricao-e-dicionario-de-dados.pdf>

[^5]: Voc√™ pode tamb√©m utilizar solu√ß√µes locais que emulem S3, como [MinIO](https://www.min.io/), [RustFS](https://rustfs.com/) ou [SeaweedFS](https://seaweedfs.com/).

[^6]: Envie as credenciais de acesso ao bucket S3 utilizado para o e-mail de contato, caso seja necess√°rio para a avalia√ß√£o da solu√ß√£o. Lembre-se de n√£o expor chaves de acesso ou informa√ß√µes sens√≠veis no c√≥digo, utilize vari√°veis de ambiente ou arquivos de configura√ß√£o para isso. Ap√≥s a avalia√ß√£o, sinta-se √† vontade para excluir os arquivos e credenciais do bucket S3 utilizado.
